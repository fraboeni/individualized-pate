{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "arabic-nelson",
            "metadata": {},
            "source": [
                "# This notebook supports the creation of overview tables for experiments on the MNIST and SVHN datasets.\n",
                "\n",
                "(used for table 1 in the paper)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "final-assistant",
            "metadata": {},
            "source": [
                "Organize imports, set constants, and load result files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "decimal-probability",
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from matplotlib.lines import Line2D\n",
                "import seaborn as sns\n",
                "from ast import literal_eval\n",
                "import os\n",
                "import yaml\n",
                "import json\n",
                "from pathlib import Path\n",
                "from os.path import expanduser\n",
                "HOME = expanduser(\"~\")\n",
                "\n",
                "voting_name = 'stats_votings.csv'\n",
                "teachers_name = \"stats_teachers.csv\"\n",
                "\n",
                "\n",
                "\n",
                "def read_yaml(yaml_path):\n",
                "    with open(yaml_path, 'r') as stream:\n",
                "        return yaml.safe_load(stream)\n",
                "\n",
                "\n",
                "BASE_YAML_PATH = os.path.join(HOME, \"/code/personalized-pate/per-point-pate/experiment_plans/set_5_paper_submission\")\n",
                "BASE_YAML_PATH = os.path.join(HOME, \"code/personalized-pate/per-point-pate/experiment_plans/set_6_reviewer_response\")\n",
                "\n",
                "DATA_DIR = os.path.join(HOME,\"datadrive_individualized_pate/reviewer_response/round_2/\")\n",
                "\n",
                "def get_config_from_experiment_name(experiment_name, verbose = False, BASE_YAML_PATH = BASE_YAML_PATH):\n",
                "    # get the epsilons\n",
                "    # get the algo\n",
                "    # get the distribution\n",
                "    \n",
                "    # step 1 : find the yaml and open it\n",
                "    # step 2 : extra the info\n",
                "    base_path = Path(BASE_YAML_PATH)\n",
                "    paths = list(base_path.glob(f\"**/{experiment_name}.yaml\"))\n",
                "    if len(paths) != 1:\n",
                "        raise Exception(f\"{experiment_name} - Unexpected number of paths - {len(paths)}\")\n",
                "    if verbose:\n",
                "        print(paths)\n",
                "    return read_yaml(paths[0]) \n",
                "\n",
                "def get_relevant_data_from_config(config):\n",
                "    \"\"\" get algo, epsilons, distributions from config\"\"\"\n",
                "    algo, epsilons = list(config[\"pate\"][\"budgets\"].items())[0]\n",
                "    epsilons = epsilons[0] # its a list of lists, for some reason\n",
                "    distributions = config[\"pate\"][\"distributions\"][0][0]\n",
                "    return algo, epsilons, distributions\n",
                "\n",
                "def get_cost_curve(experiment_name):\n",
                "    \"\"\" \"\"\"\n",
                "    OUT_PATH = os.path.join(DATA_DIR, experiment_name)\n",
                "    df_v = pd.read_csv(os.path.join(OUT_PATH, voting_name))\n",
                "    cost_curve = json.loads(df_v[\"costs_curve\"].iloc[-1])    \n",
                "    return cost_curve\n",
                "\n",
                "def get_data_frame(experiment_name, DATA_DIR = DATA_DIR):\n",
                "    \"\"\" \"\"\"\n",
                "    OUT_PATH = os.path.join(DATA_DIR, experiment_name)\n",
                "    return pd.read_csv(os.path.join(OUT_PATH, voting_name))\n",
                "\n",
                "def get_labels_generated_from_cost_curve(cost_curve, epsilons):\n",
                "    \"\"\" \"\"\"\n",
                "    return sum(np.array([under_budget(cost_curve[i], epsilons) for i in range(len(cost_curve))]))\n",
                "\n",
                "\n",
                "def get_labels_generated(experiment_name, config_path, epsilons, DATA_DIR =DATA_DIR):\n",
                "    \"\"\" \"\"\"\n",
                "    \n",
                "    OUT_PATH = os.path.join(DATA_DIR, experiment_name)\n",
                "    # baseline\n",
                "    with open(config_path, 'r') as stream:\n",
                "        config = yaml.safe_load(stream)\n",
                "    cost_curve = get_cost_curve(experiment_name)\n",
                "    \n",
                "    labels_answered = sum(np.array([under_budget(cost_curve[i], epsilons) for i in range(len(cost_curve))]))\n",
                "    #grouped_labels_answered = []\n",
                "    #if isinstance(cost_curve[0], list):\n",
                "    #    print(cost_curve[0])\n",
                "    #    for j in range(len(cost_curve[0])):\n",
                "    #        print(j)\n",
                "    #        grouped_labels_answered.append(sum(np.array([cost_curve[i][j]< epsilons[i][j] for i in range(len(cost_curve))])))\n",
                "    return labels_answered #, grouped_labels_answered\n",
                "\n",
                "\n",
                "def under_budget(costs, max_epsilons):\n",
                "    \"\"\" returns bool if all costs are under budget\"\"\"\n",
                "    \n",
                "    return all([costs[i] < max_epsilons[i] for i in range(len(costs))])\n",
                "\n",
                "\n",
                "\n",
                "def get_algo_name(exp_name):\n",
                "    names = {\"upsample\":\"upsampling\", \"weight\":\"weighting\", \"vanish\" : \"vanishing\", \"pate\":\"pate\"}\n",
                "    for name in names.keys():\n",
                "        if name in exp_name:\n",
                "            return names[name]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "740b3c75",
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_costs(cost_curve, cost_curve_b, epsilons):\n",
                "    plt.figure(figsize= (10,10))\n",
                "    plt.title(f\"{experiment}\", fontsize=18)\n",
                "    x_range = min(len(cost_curve), 2000)\n",
                "    \n",
                "    c1 = \"mediumpurple\"\n",
                "    c2 = \"blue\"\n",
                "    \n",
                "    \n",
                "    labels_answered = sum(np.array([under_budget(cost_curve[i], epsilons) for i in range(len(cost_curve))]))\n",
                "    labels_answered_b = sum(np.array([under_budget(cost_curve_b[i], epsilons) for i in range(len(cost_curve_b))]))\n",
                "    labels_answered1 = sum(np.array([cost_curve[i][0] < epsilons[0] for i in range(len(cost_curve))]))\n",
                "    \n",
                "    plt.axvline(x=labels_answered1, c= c1)\n",
                "    plt.axhline(y=epsilons[0], color=c1, linestyle='-')\n",
                "    plt.axvline(x=labels_answered_b, c= \"tab:gray\")\n",
                "    \n",
                "    if len(cost_curve[0]) >1:\n",
                "        labels_answered2 = sum(np.array([cost_curve[i][1] < epsilons[1] for i in range(len(cost_curve))]))\n",
                "        plt.axvline(x=labels_answered2, c= c2)\n",
                "        plt.plot([np.array(cost_curve[i][1]) for i in range(labels_answered)], \"-\", c= c2, label = f\"{algo_name} (high)\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "        plt.plot([np.array(cost_curve[i][1]) for i in range(x_range)], \":\", c = c2) #, labels = (\"1\", \"2\", \"3\"))\n",
                "        plt.axhline(y=epsilons[1], color=c2, linestyle='-')\n",
                "        \n",
                "    if len(cost_curve[0]) >2:\n",
                "        labels_answered3 = sum(np.array([cost_curve[i][2] < epsilons[2] for i in range(len(cost_curve))]))\n",
                "        plt.axvline(x=labels_answered3, c= 'g')\n",
                "        plt.plot([np.array(cost_curve[i][2]) for i in range(labels_answered)], \"-\", c = \"g\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "        plt.plot([np.array(cost_curve[i][2]) for i in range(x_range)], \":\", c= \"g\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "        plt.axhline(y=epsilons[2], color='g', linestyle='-', label = f\"eps = {epsilons[2]}\")\n",
                "    \n",
                "    \n",
                "\n",
                "    plt.plot([np.array(cost_curve[i][0]) for i in range(labels_answered)], \"-\", c= c1, label = f\"{algo_name} (low)\")\n",
                "    plt.plot([np.array(cost_curve[i][0]) for i in range(x_range)], \":\", c = c1)\n",
                "    \n",
                "    \n",
                "    ##  PATE plots\n",
                "    plt.plot([np.array(cost_curve_b[i]) for i in range(labels_answered_b)], \"-\", c= \"tab:gray\", label = \"pate\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "    plt.plot([np.array(cost_curve_b[i]) for i in range(min(len(cost_curve_b), 2000))], \":\", c = \"tab:gray\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "    \n",
                "        \n",
                "    plt.ylabel(\"Privacy Budget\", fontsize=18)\n",
                "    plt.xlabel(\"Labels Answered\", fontsize=18)\n",
                "    plt.legend(fontsize=12)\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "38c54fbb",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "epsilons_= [1.,2.,3.]\n",
                "epsilons_2 = [ np.around(np.log(2),2), np.around(np.log(8),2)]\n",
                "pate_epsilons = epsilons_\n",
                "\n",
                "experiments = [\"vanish\", \"mnist_vanish_row_2__2\"]\n",
                "\n",
                "DATA_DIR = os.path.join(HOME, \"datadrive_individualized_pate/reviewer_response/round_2/\")\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8454d2d3",
            "metadata": {},
            "outputs": [],
            "source": [
                "pate_config_path = os.path.join(yaml_base_path, \"mnist_pate_row_1.yaml\")\n",
                "\n",
                "df_vb = pd.read_csv(os.path.join(DATA_DIR, \"mnist_pate_row_1__exp_3\", voting_name))\n",
                "\n",
                "with open(pate_config_path, 'r') as stream:\n",
                "    pate_config = yaml.safe_load(stream)\n",
                "cost_curve_b = json.loads(df_vb[\"costs_curve\"].iloc[0])\n",
                "\n",
                "labels_answered_b = sum(np.array([under_budget(cost_curve_b[i], pate_epsilons) for i in range(len(cost_curve_b))]))\n",
                "\n",
                "print(f\"PATE - labels_answered: {labels_answered_b}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bd91b8c7",
            "metadata": {},
            "outputs": [],
            "source": [
                "experiment_groups = {\n",
                "#    \"mnist_row_1\" : {},\n",
                "#    \"mnist_row_2\" : {},\n",
                "    \"svhn_row_1\" : {},\n",
                "    \"svhn_row_2\" : {}    \n",
                "}\n",
                "\n",
                "experiments = []\n",
                "\n",
                "for group_name, exp_groups in experiment_groups.items():\n",
                "    dataset_name = group_name.split(\"_\")[0]\n",
                "    row = group_name.split(\"_\")[-1]\n",
                "    for e_name in [\"pate\", \"vanish\", \"upsample\", \"weight\"]:\n",
                "\n",
                "        exp_groups[e_name] = {}\n",
                "        \n",
                "        for i in [0,1,2,3,4,5, 6, 7]:\n",
                "            exp_groups[e_name][f\"{dataset_name}_{e_name}_row_{row}__exp_{i}\"] = 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7ba43fca",
            "metadata": {},
            "outputs": [],
            "source": [
                "experiment_groups[\"svhn_row_1\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c220eecc",
            "metadata": {},
            "outputs": [],
            "source": [
                "results = {}\n",
                "\n",
                "DATA_DIR = os.path.join(HOME,\"datadrive_individualized_pate/reviewer_response/round_2/\")\n",
                "DATA_DIR = os.path.join(HOME,\"code/data/out/\")\n",
                "\n",
                "for exp_group_name, exp_group in experiment_groups.items():\n",
                "    # mnist_row_1\n",
                "    dataset_name = exp_group_name.split(\"_\")[0]\n",
                "    yaml_base_path = os.path.join(HOME, f\"code/personalized-pate/per-point-pate/experiment_plans/set_6_reviewer_response/{dataset_name}_table_1\")\n",
                "    \n",
                "    print(dataset_name)\n",
                "    for group_name in exp_group.keys():\n",
                "        # upsample\n",
                "        \n",
                "        experiments = list(exp_group[group_name].keys())\n",
                "        print(f\"\\t {group_name}\")\n",
                "        print(experiments)\n",
                "        \n",
                "        for experiment in experiments:  \n",
                "            algo_name = get_algo_name(experiment)    \n",
                "            yaml_filename = experiment[:-len(\"__exp_3\")]\n",
                "            yaml_name = f\"{yaml_filename}.yaml\"\n",
                "\n",
                "            config = get_config_from_experiment_name(yaml_filename)\n",
                "            algo, epsilons, distributions = get_relevant_data_from_config(config)\n",
                "            config_path = os.path.join(yaml_base_path, yaml_name)\n",
                "\n",
                "            if algo not in results:\n",
                "                results[algo_name] = []\n",
                "            try :\n",
                "                labels_answered = get_labels_generated(experiment, config_path, epsilons)\n",
                "            except Exception as e:\n",
                "                print(e)\n",
                "                continue\n",
                "\n",
                "            OUT_PATH = os.path.join(DATA_DIR, experiment)\n",
                "            df_v = pd.read_csv(os.path.join(OUT_PATH, voting_name))\n",
                "            \n",
                "            # experiment = f\"{experiment}\" if \"mnist\" in experiment else f\"mnist_{experiment}\" \n",
                "\n",
                "\n",
                "            print(f\"epsilons : {epsilons}\")\n",
                "\n",
                "            print(\"-------\")\n",
                "            print(f\"{experiment} - labels_answered: {labels_answered}\")\n",
                "            # log it in the dictionary\n",
                "            exp_group[group_name][experiment] = labels_answered\n",
                "\n",
                "            plotting = False\n",
                "            if plotting:\n",
                "                cost_curve = get_cost_curve(experiment_name)\n",
                "                epsilons = epsilons_2 if len(cost_curve[0]) ==2 else epsilons_\n",
                "\n",
                "                # PLOT VOTING MECHANISM VS LABEL COUNT\n",
                "\n",
                "                #for i, labels_answered_group in enumerate(labels_answered_groups):\n",
                "                #    print(f\"{experiment} - labels_answered ({i}): {labels_answered_group}\")\n",
                "                print(f\"{experiment} - {algo}: accuracy: {df_v['accuracy'].mean()}\")\n",
                "                plot_costs(cost_curve,cost_curve_b, epsilons)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "85513ecb",
            "metadata": {},
            "outputs": [],
            "source": [
                "experiment_groups[\"svhn_row_1\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3927909b",
            "metadata": {},
            "source": [
                "# exp_groups_row_2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "547324a6",
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": [
                "##\n",
                "## Generate figure for figure 2\n",
                "##\n",
                "\n",
                "def under_budget(costs, max_epsilons):\n",
                "    \"\"\" returns bool if all costs are under budget\"\"\"    \n",
                "    return all([costs[i] < max_epsilons[i] for i in range(len(costs))])\n",
                "\n",
                "\n",
                "epsilons = [ np.around(np.log(2),2), np.around(np.log(8),2)]\n",
                "pate_epsilons = epsilons_2\n",
                "\n",
                "voting_name = 'stats_votings.csv'\n",
                "DATA_DIR = os.path.join(HOME,\"datadrive_individualized_pate/\")\n",
                "yaml_base_path = os.path.join(HOME,\"code/personalized-pate/per-point-pate/experiment_plans/set_5_paper_submission/\")\n",
                "BASELINE_PATH= f\"{DATA_DIR}/pate/\"\n",
                "\n",
                "#\n",
                "# baseline pate\n",
                "#\n",
                "pate_config_path = os.path.join(yaml_base_path, \"mnist_pate.yaml\")\n",
                "df_vb = pd.read_csv(os.path.join(BASELINE_PATH, voting_name))\n",
                "with open(pate_config_path, 'r') as stream:\n",
                "    pate_config = yaml.safe_load(stream)\n",
                "cost_curve_b = json.loads(df_vb[\"costs_curve\"].iloc[0])\n",
                "labels_answered_b = sum(np.array([under_budget(cost_curve_b[i], epsilons) for i in range(len(cost_curve_b))]))\n",
                "##\n",
                "\n",
                "\n",
                "#\n",
                "# upsampling\n",
                "#\n",
                "experiment = \"upsample_figure_2\"   \n",
                "algo_name = \"upsampling\"\n",
                "yaml_name = f\"mnist_{experiment}.yaml\"    \n",
                "config_path = os.path.join(yaml_base_path, yaml_name)\n",
                "OUT_PATH = os.path.join(DATA_DIR, experiment)\n",
                "\n",
                "\n",
                "\n",
                "#\n",
                "# configs\n",
                "#\n",
                "with open(config_path, 'r') as stream:\n",
                "    config = yaml.safe_load(stream)\n",
                "algo = list(config[\"pate\"][\"budgets\"].keys())[0]\n",
                "distributions = config[\"pate\"][\"distributions\"][0][0]\n",
                "\n",
                "\n",
                "\n",
                "#\n",
                "# labels answered\n",
                "#\n",
                "df_v = pd.read_csv(os.path.join(OUT_PATH, voting_name))\n",
                "cost_curve = json.loads(df_v[\"costs_curve\"].iloc[0])\n",
                "\n",
                "labels_answered = sum(np.array([under_budget(cost_curve[i], epsilons) for i in range(len(cost_curve))]))\n",
                "labels_answered1 = sum(np.array([cost_curve[i][0] < epsilons[0] for i in range(len(cost_curve))]))\n",
                "labels_answered2 = sum(np.array([cost_curve[i][1] < epsilons[1] for i in range(len(cost_curve))]))\n",
                "\n",
                "\n",
                "## \n",
                "## plots\n",
                "##\n",
                "\n",
                "c1 = \"mediumpurple\"#\"mediumpurple\"\n",
                "c2 = \"blue\" #\"blue\"\n",
                "pate_c = \"tab:gray\"\n",
                "\n",
                "hor_line_alpha = 0.6\n",
                "vert_line_alpha = 0.75\n",
                "\n",
                "hor_line_style = \"dashdot\"\n",
                "vert_line_style = \"-\"\n",
                "\n",
                "big_font = 20\n",
                "small_font = 18\n",
                "\n",
                "plt.figure(figsize= (15,8))\n",
                "plt.ylim(0, top = 3.5)\n",
                "\n",
                "\n",
                "# hor lines\n",
                "\n",
                "plt.axhline(y=epsilons[0], color=c1, linestyle=hor_line_style, alpha =hor_line_alpha)    \n",
                "plt.axhline(y=epsilons[1], color=c2, linestyle=hor_line_style, alpha =hor_line_alpha)\n",
                "plt.text(1350, epsilons[0]+ .025, 'low budget : log(2)', fontsize = small_font)\n",
                "plt.text(1350, epsilons[1] + .025,'high budget : log(8)', fontsize = small_font)\n",
                "\n",
                "# vertical lines:\n",
                "plt.plot((labels_answered1,labels_answered1),(0, epsilons[0]), c= c1, linestyle= vert_line_style,alpha = vert_line_alpha)\n",
                "plt.plot((labels_answered2,labels_answered2),(0, epsilons[1]), c= c2, linestyle= vert_line_style, alpha = vert_line_alpha)\n",
                "# pate vertical lines\n",
                "plt.plot((labels_answered_b,labels_answered_b),(0, epsilons[0]), c= pate_c, linestyle= vert_line_style, alpha = vert_line_alpha)\n",
                "\n",
                "# pate stopping points\n",
                "plt.scatter((labels_answered_b-1), (cost_curve_b[labels_answered_b-1][0]), c= \"orange\", label = \"pate stopping point\")\n",
                "\n",
                "\n",
                "x_range = min(len(cost_curve), 2000)\n",
                "plt.plot([np.array(cost_curve[i][1]) for i in range(labels_answered)], \"-\", c= c2, label = f\"{algo_name} (high)\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "plt.plot([np.array(cost_curve[i][1]) for i in range(x_range)], \":\", c = c2) #, labels = (\"1\", \"2\", \"3\"))\n",
                "\n",
                "plt.plot([np.array(cost_curve[i][0]) for i in range(labels_answered)], \"-\", c= c1, label = f\"{algo_name} (low)\")\n",
                "plt.plot([np.array(cost_curve[i][0]) for i in range(x_range)], \":\", c = c1)\n",
                "\n",
                "\n",
                "# stopping points\n",
                "plt.scatter((labels_answered, labels_answered), \n",
                "            (cost_curve[labels_answered][0], cost_curve[labels_answered][1]),\n",
                "            c = \"red\",\n",
                "           label = \"upsampling stopping point\")\n",
                "\n",
                "\n",
                "\n",
                "#\n",
                "##  PATE plots\n",
                "#\n",
                "plt.plot([np.array(cost_curve_b[i]) for i in range(labels_answered_b)], \"-\", c= pate_c, label = \"pate\")\n",
                "plt.plot([np.array(cost_curve_b[i]) for i in range(min(len(cost_curve_b), 2000))], \":\", c = pate_c) \n",
                "\n",
                "\n",
                "\n",
                "\n",
                "# labels\n",
                "plt.xticks(fontsize= small_font)\n",
                "plt.yticks(fontsize= small_font)\n",
                "\n",
                "plt.ylabel(\"Privacy Budget\", fontsize=big_font)\n",
                "plt.xlabel(\"Number of Generated Labels\", fontsize=big_font)\n",
                "plt.legend(fontsize=small_font)\n",
                "\n",
                "save_path = os.path.join(HOME,\"assets/upsampling_demo.pdf\")\n",
                "print(save_path)\n",
                "plt.savefig(save_path)  \n",
                "\n",
                "plt.show()\n",
                "\n",
                "#\n",
                "# text\n",
                "\n",
                "print(f\"PATE - labels_answered: {labels_answered_b}\")\n",
                "print(f\"PATE - accuracy: {df_vb['accuracy'].mean()}\")\n",
                "print(\"-------\")\n",
                "print(f\"{experiment} - labels_answered: {labels_answered}\")\n",
                "print(f\"{experiment} - labels_answered (0): {labels_answered1}\")\n",
                "print(f\"{experiment} - labels_answered (1):  {labels_answered2}\")\n",
                "#print(f\"{experiment} - labels_answered (2): {labels_answered3}\")\n",
                "print(f\"{experiment} - {algo}: accuracy: {df_v['accuracy'].mean()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2bff987a",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "96226153",
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": [
                "##\n",
                "## Table 4\n",
                "##\n",
                "\n",
                "\n",
                "\n",
                "epsilons_= [1.,2.,3.]\n",
                "epsilons_2 = [ np.around(np.log(2),2), np.around(np.log(8),2)]\n",
                "\n",
                "\n",
                "pate_epsilons = epsilons_\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "experiments = [\n",
                "\n",
                "    #mnist_weight_75_25__ln4\",  \n",
                "    #mnist_weight_75_25__ln4__2\",\n",
                "    #mnist_weight_50_50__ln4\",\n",
                "    #\"mnist_weight_25_75__ln4\",  \n",
                "    \n",
                "    \"mnist_weight_75_25__ln8\",\n",
                "    \"mnist_weight_75_25__ln8__2\",\n",
                "    #\"mnist_weight_50_50__ln8\",    \n",
                "    #\"mnist_weight_25_75__ln8\",\n",
                "    \n",
                "    \n",
                "    \"mnist_weight_75_25__ln16\",\n",
                "    #\"mnist_weight_50_50__ln16\",\n",
                "    #\"mnist_weight_25_75__ln16\",\n",
                "]\n",
                "\n",
                "\n",
                "voting_name = 'stats_votings.csv'\n",
                "teachers_name = \"stats_teachers.csv\"\n",
                "\n",
                "yaml_base_path = os.path.join(HOME, \"code/personalized-pate/per-point-pate/experiment_plans/set_5_paper_submission/\")\n",
                "DATA_DIR = os.path.join(HOME,\"datadrive_individualized_pate/\")\n",
                "\n",
                "\n",
                "BASELINE_PATH= f\"{DATA_DIR}/pate/\"\n",
                "\n",
                "pate_config_path = os.path.join(yaml_base_path, \"mnist_pate.yaml\")\n",
                "df_vb = pd.read_csv(os.path.join(BASELINE_PATH, voting_name))\n",
                "with open(pate_config_path, 'r') as stream:\n",
                "    pate_config = yaml.safe_load(stream)\n",
                "cost_curve_b = json.loads(df_vb[\"costs_curve\"].iloc[0])\n",
                "\n",
                "\n",
                "#yaml_base_path = os.path.join(yaml_base_path,\"table_4_weighting\")\n",
                "\n",
                "\n",
                "DATA_DIR = os.path.join(HOME,\"code/data/out/\")\n",
                "\n",
                "experiments = [\"mnist_weight_50_50__ln8__3\"]\n",
                "experiments = [\"mnist_vanish_row_2__2\", \"mnist_vanish_row_2__3\"] # beep boop baap\n",
                "experiments = [\"mnist_vanish_table_4__3\"] # beep boop baap\n",
                "\n",
                "for experiment in experiments:  \n",
                "    algo_name = get_algo_name(experiment)\n",
                "    yaml_name = f\"{experiment}.yaml\"\n",
                "    config_path = os.path.join(yaml_base_path, yaml_name)\n",
                "    \n",
                "    print(config_path)\n",
                "    OUT_PATH = os.path.join(DATA_DIR, experiment)\n",
                "    df_v = pd.read_csv(os.path.join(OUT_PATH, voting_name))\n",
                "    \n",
                "    experiment = f\"{experiment}\"\n",
                "\n",
                "    # baseline\n",
                "    with open(config_path, 'r') as stream:\n",
                "        config = yaml.safe_load(stream)\n",
                "\n",
                "    algo = list(config[\"pate\"][\"budgets\"].keys())[0]\n",
                "    distributions = config[\"pate\"][\"distributions\"][0][0]\n",
                "    print(distributions)\n",
                "    #epsilons = sorted(json.loads(df_v[\"eps_short\"].iloc[0]))\n",
                "    #epsilons = np.log(np.array([2,16]))\n",
                "    epsilons = epsilons_\n",
                "    epsilons = [np.log(2), np.log(8)]\n",
                "    \n",
                "    cost_curve = json.loads(df_v[\"costs_curve\"].iloc[-1])\n",
                "    print(cost_curve[0])\n",
                "    print(\"epsilons:\")\n",
                "    print(epsilons)\n",
                "    \n",
                "\n",
                "    labels_answered = sum(np.array([under_budget(cost_curve[i], epsilons) for i in range(len(cost_curve))]))\n",
                "    \n",
                "    labels_answered1 = sum(np.array([cost_curve[i][0] < epsilons[0] for i in range(len(cost_curve))]))\n",
                "    labels_answered2 = sum(np.array([cost_curve[i][1] < epsilons[1] for i in range(len(cost_curve))]))\n",
                "    #labels_answered3 = sum(np.array([cost_curve[i][2] < epsilons[1] for i in range(len(cost_curve))]))\n",
                "\n",
                "\n",
                "    print(\"-------\")\n",
                "    #print(f\"epsilons : {epsilons}\")\n",
                "    exponents = np.around(np.exp(np.array(epsilons)),0) \n",
                "    print(f\"epsilons: \\n[ln({int(exponents[0])}), ln({int(exponents[1])})]\")\n",
                "    name = experiment[len(\"mnist_weight_\"): len(\"mnist_weight_25_75\")]\n",
                "    print(\" \" + \"% -\".join(name.split(\"_\")) + \"%\")\n",
                "    title = f\"{distributions[0]}% - {distributions[1]}% \"# \"- {distributions[2]}%\"\n",
                "    print(title)\n",
                "    title += \"  \" + algo\n",
                "    #print(f\"{experiment} - {algo}: number of votes: {df_v['n_votings'].mean()}\")\n",
                "    print(f\"\\t\\t{experiment} - labels_answered: {labels_answered}\")\n",
                "    \n",
                "    # pate\n",
                "    labels_answered_b = sum(np.array([under_budget(cost_curve_b[i], epsilons) for i in range(len(cost_curve_b))]))\n",
                "    print(f\"\\t\\tPATE - labels_answered: {labels_answered_b}\")\n",
                "    #print(f\"PATE - accuracy: {df_vb['accuracy'].mean()}\")\n",
                "\n",
                "    \n",
                "        \n",
                "    c1 = \"mediumpurple\"\n",
                "    c2 = \"blue\"\n",
                "    \n",
                "    plt.figure(figsize= (10,10))\n",
                "    #plt.title(f\"{experiment}\", fontsize=18)\n",
                "    plt.title(title)\n",
                "    x_range = min(len(cost_curve), 2000)\n",
                "    plt.plot([np.array(cost_curve[i][0]) for i in range(labels_answered)], \"-\", c= c1, label = f\"{algo_name} (low)\")\n",
                "    plt.plot([np.array(cost_curve[i][0]) for i in range(x_range)], \":\", c = c1)\n",
                "    if len(cost_curve[0])>1:\n",
                "        plt.plot([np.array(cost_curve[i][1]) for i in range(labels_answered)], \"-\", c= c2, label = f\"{algo_name} (high)\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "        plt.plot([np.array(cost_curve[i][1]) for i in range(x_range)], \":\", c = c2) #, labels = (\"1\", \"2\", \"3\"))\n",
                "\n",
                "    if len(cost_curve[0]) >2:\n",
                "        plt.plot([np.array(cost_curve[i][2]) for i in range(labels_answered)], \"-\", c = \"g\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "        plt.plot([np.array(cost_curve[i][2]) for i in range(x_range)], \":\", c= \"g\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "    \n",
                "    \n",
                "    plt.axvline(x=labels_answered1, c= c1)\n",
                "    plt.axvline(x=labels_answered2, c= c2)\n",
                "    if len(cost_curve[0]) >2:\n",
                "        plt.axvline(x=labels_answered3, c= 'g')\n",
                "\n",
                "    #plt.axhline(y=epsilons[0], color='r', linestyle='-', label = f\"Most Private (eps = {epsilons[0]})\")\n",
                "    #hack -hard code legends\n",
                "    plt.axhline(y=epsilons[0], color=c1, linestyle='-')\n",
                "    if len(epsilons) >1:\n",
                "        #plt.axhline(y=epsilons[1], color='b', linestyle='-', label = f\"Least Private (eps = {epsilons[1]})\")\n",
                "        # hack -hard code legends\n",
                "        plt.axhline(y=epsilons[1], color=c2, linestyle='-')\n",
                "        \n",
                "    if len(epsilons) >2:\n",
                "        plt.axhline(y=epsilons[2], color='g', linestyle='-', label = f\"eps = {epsilons[2]}\")\n",
                "    \n",
                "    \n",
                "    ##  PATE plots\n",
                "    plt.plot([np.array(cost_curve_b[i]) for i in range(labels_answered_b)], \"-\", c= \"tab:gray\", label = \"pate\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "    plt.plot([np.array(cost_curve_b[i]) for i in range(min(len(cost_curve_b), 2000))], \":\", c = \"tab:gray\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "    \n",
                "    plt.axvline(x=labels_answered_b, c= \"tab:gray\")\n",
                "        #(0.1, 0.2, 0.5, 0.3)\n",
                "        \n",
                "    plt.ylabel(\"Privacy Budget\", fontsize=18)\n",
                "    plt.xlabel(\"Labels Answered\", fontsize=18)\n",
                "    plt.legend(fontsize=12)\n",
                "    plt.xlim(right = 600)\n",
                "    plt.ylim((0,4))\n",
                "\n",
                "    plt.show()\n",
                "\n",
                "    #print(f\"PATE - number of votes: {df_vb['n_votings'].mean()}\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "06fb0952",
            "metadata": {},
            "outputs": [],
            "source": [
                "mnist_weight_75_25__ln8__2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "14863dac",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5fe13688",
            "metadata": {},
            "outputs": [],
            "source": [
                "# generate student accuracy table\n",
                "configs = [\n",
                "    \"mnist_weight_row_1__reweighted\",  \n",
                "    \"mnist_weight_row_2__reweighted\",  \n",
                "    \n",
                "    #\"vanish\", computing now\n",
                "    #\"mnist_vanish_row_2__2\", computing now\n",
                "    \n",
                "    \"upsample_figure_2\",\n",
                "    \"mnist_upsample_row_2__3\",\n",
                "    \n",
                "    #\"mnist_pate_row_2__2\",\n",
                "]\n",
                "\n",
                "name_mapping_dict = {\n",
                "    \"mnist_weight_row_1__reweighted\" : \"weight row 1\",  \n",
                "    \"mnist_weight_row_2__reweighted\" : \"weight row 2\",  \n",
                "    \n",
                "    #\"vanish\", computing now\n",
                "    #\"mnist_vanish_row_2__2\", computing now\n",
                "    \n",
                "    \"upsample_figure_2\" : \"upsample row 1\",\n",
                "    \"mnist_upsample_row_2__3\" : \"upsample row 2\",\n",
                "}\n",
                "BASE_YAML_PATH = os.path.join(HOME, \"code/personalized-pate/per-point-pate/experiment_plans/set_5_paper_submission/table_2_students\")\n",
                "for config_name in configs:\n",
                "    c = get_config_from_experiment_name(config_name, BASE_YAML_PATH= BASE_YAML_PATH)\n",
                "    students_csv = os.path.join(HOME,f\"datadrive_individualized_pate/{config_name}/stats_students.csv\")\n",
                "    df_s = pd.read_csv(students_csv)\n",
                "    print(f\"Student accuracy : {name_mapping_dict[config_name]} - {np.mean(df_s['test_accuracy'])}\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3c89bfa7",
            "metadata": {},
            "outputs": [],
            "source": [
                "voting_name = 'stats_votings.csv'\n",
                "teachers_name = \"stats_teachers.csv\"\n",
                "\n",
                "yaml_base_path = os.path.join(HOME,\"code/personalized-pate/per-point-pate/experiment_plans/set_5_paper_submission/upsample_weighted_ratio_plot/\")\n",
                "DATA_DIR = os.path.join(HOME,\"datadrive_individualized_pate/\")\n",
                "\n",
                "def compute_weighted_ratio(epsilons, distributions):\n",
                "    if len(epsilons) != len(distributions):\n",
                "        raise Exception(\"groups len and distributions length not the same\")\n",
                "    if sum(distributions) != 1:\n",
                "        raise Exception(\"distribution does not sum to 1\")\n",
                "    return sum(np.array(epsilons) * np.array(distributions))\n",
                "\n",
                "compute_weighted_ratio([16,4], [.75, .25])\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "73c42dca",
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_DIR = os.path.join(HOME,\"datadrive_individualized_pate/\")\n",
                "\n",
                " \n",
                "upsample_experiments=[\n",
                "\n",
                "    \"upsample_weighted_ratio_plot_25_75__1\",\n",
                "    \"upsample_weighted_ratio_plot_25_75__2\",\n",
                "    \"upsample_weighted_ratio_plot_25_75__3\", # redo this one\n",
                "    \"upsample_weighted_ratio_plot_25_75__4\",\n",
                "    \"upsample_weighted_ratio_plot_25_75__5\",\n",
                "    \"upsample_weighted_ratio_plot_25_75__6\",\n",
                "    \"upsample_weighted_ratio_plot_25_75__7\", # redo this one \n",
                "    \"upsample_weighted_ratio_plot_25_75__8\",\n",
                "\n",
                "    \"upsample_weighted_ratio_plot_1\",\n",
                "    \"upsample_weighted_ratio_plot_2\",\n",
                "    \"upsample_weighted_ratio_plot_3\",\n",
                "    \"upsample_weighted_ratio_plot_4\",\n",
                "    \"upsample_weighted_ratio_plot_5\",\n",
                "    \"upsample_weighted_ratio_plot_6\",\n",
                "    \"upsample_weighted_ratio_plot_7\",\n",
                "    \n",
                "    \"upsample_weighted_ratio_plot_75_25__1\",\n",
                "    \"upsample_weighted_ratio_plot_75_25__2\",\n",
                "    \"upsample_weighted_ratio_plot_75_25__3\",\n",
                "    \"upsample_weighted_ratio_plot_75_25__4\",\n",
                "    \"upsample_weighted_ratio_plot_75_25__5\",\n",
                "    \"upsample_weighted_ratio_plot_75_25__6\",\n",
                "    \"upsample_weighted_ratio_plot_75_25__7\",\n",
                "    \"upsample_weighted_ratio_plot_75_25__8\",\n",
                "]\n",
                "\n",
                "weight_and_vanish_experiments = [\n",
                "    \"vanish_weighted_ratio_plot_25_75__2\",\n",
                "    #\"vanish_weighted_ratio_plot_50_50__2\", # need to make this one next\n",
                "    #\"vanish_weighted_ratio_plot_75_25__2\", # making this now on nic2 (voting ~ 15 min)\n",
                "    \n",
                "    \"weight_weighted_ratio_plot_25_75__2\",\n",
                "    #\"weight_weighted_ratio_plot_50_50__2\", # just started - running on equus (~1 hour) (start - 6 pm)\n",
                "    \"weight_weighted_ratio_plot_75_25__2\", # done\n",
                "]\n",
                "extras = [\n",
                "    \"vanish_weighted_ratio_plot_25_75__2\",\n",
                "    \"vanish_weighted_ratio_plot_25_75__3\",\n",
                "    \"vanish_weighted_ratio_plot_25_75__4\",\n",
                "    \"vanish_weighted_ratio_plot_25_75__5\",\n",
                "    \"vanish_weighted_ratio_plot_25_75__6\",\n",
                "    \"vanish_weighted_ratio_plot_25_75__7\",\n",
                "    \"vanish_weighted_ratio_plot_50_50__2\",\n",
                "    \"vanish_weighted_ratio_plot_50_50__3\",\n",
                "    #\"vanish_weighted_ratio_plot_50_50__4\",\n",
                "    \"vanish_weighted_ratio_plot_75_25__2\",\n",
                "    \"vanish_weighted_ratio_plot_75_25__3\",\n",
                "    #\"weight_weighted_ratio_plot_1\",\n",
                "    \"weight_weighted_ratio_plot_75_25__2\",\n",
                "    \"weight_weighted_ratio_plot_75_25__3\",\n",
                "    \"weight_weighted_ratio_plot_75_25__4\",\n",
                "    \"weight_weighted_ratio_plot_75_25__5\",\n",
                "    \"weight_weighted_ratio_plot_75_25__6\",\n",
                "    \"weight_weighted_ratio_plot_75_25__7\",\n",
                "    \"weight_weighted_ratio_plot_75_25__8\",\n",
                "]\n",
                "\n",
                "def get_algo_name(exp_name):\n",
                "    names = {\"upsample\":\"upsampling\", \"weight\":\"weighting\", \"vanish\" : \"vanishing\", \"pate\":\"pate\"}\n",
                "    for name in names.keys():\n",
                "        if name in exp_name:\n",
                "            return names[name]\n",
                "        "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b8d5e8ba",
            "metadata": {},
            "outputs": [],
            "source": [
                "e = 3\n",
                "def get_cost_curve_for_eps(df, e=1):\n",
                "    return json.loads(df[df[\"eps_short\"] == f\"[1.0, {e}.0]\" ].iloc[-1]['costs_curve'])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "86364413",
            "metadata": {},
            "outputs": [],
            "source": [
                "from collections import defaultdict\n",
                "results_50_50 = defaultdict(lambda : [])\n",
                "\n",
                "results_25_75 = defaultdict(lambda : [])\n",
                "results_75_25 = defaultdict(lambda : [])\n",
                "\n",
                "## just upsampling\n",
                "##\n",
                "\n",
                "for i, experiment_name in enumerate(upsample_experiments): \n",
                "    #print(i)\n",
                "    algo_name = get_algo_name(experiment_name)\n",
                "    yaml_name = f\"{experiment_name}.yaml\"\n",
                "    \n",
                "    config = get_config_from_experiment_name(experiment_name)\n",
                "    algo, epsilons, distributions = get_relevant_data_from_config(config)\n",
                "    weighted_ratio = compute_weighted_ratio(epsilons, distributions)\n",
                "    if algo not in results:\n",
                "        results[algo_name] = []\n",
                "    try :\n",
                "        labels_answered = get_labels_generated(experiment_name, config_path, epsilons)\n",
                "    except Exception as e:\n",
                "        print(e)\n",
                "        continue\n",
                "    if distributions == [.5,.5]:\n",
                "        results_50_50[algo_name].append((weighted_ratio,labels_answered))\n",
                "    elif distributions == [.25,.75]:\n",
                "        results_25_75[algo_name].append((weighted_ratio,labels_answered))\n",
                "    elif distributions == [.75,.25]:\n",
                "        results_75_25[algo_name].append((weighted_ratio,labels_answered))\n",
                "    else :\n",
                "        print(\"UHOH\")\n",
                "        print(distributions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6f42f9dc",
            "metadata": {},
            "outputs": [],
            "source": [
                "weight_and_vanish_experiments = [#\"weight_weighted_ratio_plot_25_75__all\", # looks good\n",
                "                                #\"weight_weighted_ratio_plot_50_50__all2\" # need to rerun\n",
                "                                #\"weight_weighted_ratio_plot_75_25__all\" # need to rerun\n",
                "]\n",
                "\n",
                "weight_and_vanish_experiments = [\n",
                "                    #\"vanish_weighted_ratio_plot_25_75__all2\",\n",
                "                    #\"vanish_weighted_ratio_plot_50_50__all2\",\n",
                "                    \n",
                "                    #\"weight_weighted_ratio_plot_50_50__all2\",\n",
                "                    #\"vanish_weighted_ratio_plot_75_25__all\" , # this one worked for some reason\n",
                "                    #\"weight_weighted_ratio_plot_25_75__all\",\n",
                "    \"weight_weighted_ratio_plot_25_75__2\",\n",
                "    \"weight_weighted_ratio_plot_25_75__3\",\n",
                "    \"weight_weighted_ratio_plot_25_75__4\",\n",
                "    \"weight_weighted_ratio_plot_25_75__5\",\n",
                "    \"weight_weighted_ratio_plot_25_75__6\",\n",
                "    \"weight_weighted_ratio_plot_25_75__7\",\n",
                "    \"weight_weighted_ratio_plot_25_75__8\",\n",
                "    \"weight_weighted_ratio_plot_25_75__9\",\n",
                "    \"weight_weighted_ratio_plot_25_75__10\",\n",
                "    \"weight_weighted_ratio_plot_25_75__11\",\n",
                "    \"weight_weighted_ratio_plot_25_75__12\",\n",
                "    \n",
                "    \"weight_weighted_ratio_plot_50_50__2\",\n",
                "    \"weight_weighted_ratio_plot_50_50__3\",\n",
                "    \"weight_weighted_ratio_plot_50_50__4\",\n",
                "    \"weight_weighted_ratio_plot_50_50__5\",\n",
                "    \"weight_weighted_ratio_plot_50_50__6\",\n",
                "    \"weight_weighted_ratio_plot_50_50__7\",\n",
                "\n",
                "    \"weight_weighted_ratio_plot_75_25__2\",\n",
                "    \"weight_weighted_ratio_plot_75_25__3\",\n",
                "    \"weight_weighted_ratio_plot_75_25__4\",\n",
                "    \"weight_weighted_ratio_plot_75_25__5\",\n",
                "    \"weight_weighted_ratio_plot_75_25__6\",\n",
                "    \"weight_weighted_ratio_plot_75_25__7\",\n",
                "    \"weight_weighted_ratio_plot_75_25__8\",\n",
                "    \"weight_weighted_ratio_plot_75_25__9\",\n",
                "    \"weight_weighted_ratio_plot_75_25__10\",\n",
                "    \"weight_weighted_ratio_plot_75_25__11\",\n",
                "    \"weight_weighted_ratio_plot_75_25__12\",\n",
                "    \"weight_weighted_ratio_plot_75_25__13\",\n",
                "    \"weight_weighted_ratio_plot_75_25__14\",\n",
                "    \"weight_weighted_ratio_plot_75_25__15\",\n",
                "\n",
                "    ###\"weight_weighted_ratio_plot_75_25__all\", # just kicked off\n",
                "]\n",
                "\n",
                "DATA_DIR1 = os.path.join(HOME,\"datadrive_individualized_pate/\")\n",
                "DATA_DIR2 = os.path.join(HOME,\"code/data/out\")\n",
                "\n",
                "for i, experiment_name in enumerate(weight_and_vanish_experiments): \n",
                "    #print(i)\n",
                "    algo_name = get_algo_name(experiment_name)\n",
                "    yaml_name = f\"{experiment_name}.yaml\"\n",
                "    try:\n",
                "        config = get_config_from_experiment_name(experiment_name)\n",
                "    except:\n",
                "        continue\n",
                "    algo, epsilons, distributions = get_relevant_data_from_config(config)\n",
                "    try:\n",
                "        df = get_data_frame(experiment_name, DATA_DIR = DATA_DIR1)\n",
                "    except:\n",
                "        try:\n",
                "            df = get_data_frame(experiment_name, DATA_DIR =DATA_DIR2 )\n",
                "        except:\n",
                "            print(f\"nope on {experiment_name}\")\n",
                "            continue\n",
                "\n",
                "    if algo not in results:\n",
                "        results[algo_name] = []\n",
                "    \n",
                "    for epsilon_2 in range(1,8+1):\n",
                "        epsilons = [1., epsilon_2*1.]\n",
                "        try :\n",
                "            cost_curve = get_cost_curve_for_eps(df, e=epsilon_2)\n",
                "        except:\n",
                "            #print(f\"failed for {epsilon_2}\")\n",
                "            continue\n",
                "        plot = False\n",
                "        if plot:\n",
                "            #plot_costs(cost_curve, cost_curve, [1.,epsilon_2])\n",
                "\n",
                "            plt.plot(cost_curve)\n",
                "            plt.axhline(1.)\n",
                "            plt.axhline(epsilon_2)\n",
                "        \n",
                "        labels_answered = get_labels_generated_from_cost_curve(cost_curve, epsilons)\n",
                "\n",
                "        print(f\"{algo_name} {distributions} eps (1., {epsilon_2}): {labels_answered}\")\n",
                "        weighted_ratio = compute_weighted_ratio(epsilons, distributions)\n",
                "        if distributions == [.5,.5]:\n",
                "            results_50_50[algo_name].append((weighted_ratio,labels_answered))\n",
                "        elif distributions == [.25,.75]:\n",
                "            results_25_75[algo_name].append((weighted_ratio,labels_answered))\n",
                "        elif distributions == [.75,.25]:\n",
                "            results_75_25[algo_name].append((weighted_ratio,labels_answered))\n",
                "        else :\n",
                "            print(\"UHOH\")\n",
                "            print(distributions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2490d44d",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "plt.figure(figsize = (10,10))\n",
                "big_font = 20\n",
                "small_font = 17\n",
                "markersize=70\n",
                "\n",
                "#plt.title(\"Generated Labels vs Ratio between epsilons\", fontsize = 16)\n",
                "flip = True\n",
                "if flip:\n",
                "    #plt.xlim(0, 3300)\n",
                "    plt.ylim((0., 3.6))\n",
                "    plt.xlabel(\"Generated Labels\", fontsize = big_font)\n",
                "    plt.ylabel(\"Weighted Privacy Ratio $(d_1 \\cdot \\epsilon_1) / (d_0 \\cdot \\epsilon_0)$\", fontsize = big_font)\n",
                "\n",
                "else:\n",
                "    plt.xlim((0., 3.6))\n",
                "    plt.ylabel(\"Generated Labels\", fontsize = big_font)\n",
                "    plt.xlabel(\"Weighted Epsilon Ratio $(d_1 \\cdot \\epsilon_1) / (d_0 \\cdot \\epsilon_0)$\", fontsize = big_font)\n",
                "\n",
                "colors = {\"weighting\": \"r\", \"upsampling\" :\"blue\", \"vanishing\": \"brown\"}\n",
                "markers = {\"weighting\": \"^\", \"upsampling\" :\"+\", \"vanishing\": \".\"}\n",
                "alpha = {\"weighting\": .75, \"upsampling\" : .75, \"vanishing\": .5}\n",
                "\n",
                "skip_vanish = True\n",
                "\n",
                "for algo, ratioed_labels_generated in results_25_75.items():\n",
                "    if skip_vanish and algo == \"vanishing\":\n",
                "        continue\n",
                "    x,y =list(zip(*ratioed_labels_generated))\n",
                "    if flip:\n",
                "        x,y = y,x\n",
                "    algo_name = algo\n",
                "    if \"weight\" in algo:\n",
                "        algo_name += \"   \"\n",
                "    plt.scatter(x,y , label = f\"{algo_name} - 25%-75%\", marker =\".\", c = colors[algo], alpha = alpha[algo] , s= markersize)\n",
                "    #plt.scatter(x,y , label = f\"{algo} - 25%-75%\", marker =markers[algo], c = \"b\")\n",
                "\n",
                "for algo, ratioed_labels_generated in results_50_50.items():\n",
                "    if skip_vanish and algo == \"vanishing\":\n",
                "        continue\n",
                "    x,y =list(zip(*ratioed_labels_generated))\n",
                "    if flip:\n",
                "        x,y = y,x\n",
                "    algo_name = algo\n",
                "    if \"weight\" in algo:\n",
                "        algo_name += \"   \"\n",
                "    plt.scatter(x,y , label = f\"{algo_name} - 50%-50%\", marker =\"+\", c = colors[algo], alpha = alpha[algo], s =markersize)\n",
                "    #plt.scatter(x,y , label = f\"{algo} - 50%-50%\", marker =markers[algo], c = \"r\")\n",
                "\n",
                "for algo, ratioed_labels_generated in results_75_25.items():\n",
                "    if skip_vanish and algo == \"vanishing\":\n",
                "        continue\n",
                "    x,y =list(zip(*ratioed_labels_generated))\n",
                "    if flip:\n",
                "        x,y = y,x\n",
                "    algo_name = algo\n",
                "    if \"weight\" in algo:\n",
                "        algo_name += \"   \"\n",
                "    plt.scatter(x,y , label = f\"{algo_name} - 75%-25%\", marker =\"^\", c = colors[algo], alpha = alpha[algo], s= markersize)\n",
                "    #plt.scatter(x,y , label = f\"{algo} - 75%-25%\", marker =markers[algo], c = \"g\")\n",
                "# x0 x1 , y0 y1\n",
                "#plt.plot((0 ,3400), (0.5, 3.5))\n",
                "plt.legend(fontsize = big_font)\n",
                "plt.xticks(fontsize= small_font)\n",
                "plt.yticks(fontsize= small_font)\n",
                "\n",
                "save_path = os.path.join(HOME, \"assets/weighted_ratio_of_generated_labels.pdf\")\n",
                "print(save_path)\n",
                "plt.savefig(save_path)  \n",
                "\n",
                "\n",
                "plt.show()\n",
                "\n",
                "\n",
                "#\n",
                "# note: the reason why you see plateaus earlier, is because for some models the lower group \n",
                "# "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "47aa20bd",
            "metadata": {},
            "outputs": [],
            "source": [
                "results_75_25"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b5f12fdd",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "name = \"weight_weighted_ratio_plot_50_50__all2\"\n",
                "\n",
                "OUT_PATH = os.path.join(DATA_DIR2, name)\n",
                "with open(config_path, 'r') as stream:\n",
                "    config = yaml.safe_load(stream)\n",
                "\n",
                "df_v = pd.read_csv(os.path.join(OUT_PATH, voting_name))\n",
                "\n",
                "\n",
                "pd.set_option(\"display.max_columns\", None)\n",
                "\n",
                "e = 3\n",
                "def get_cost_curve_for_eps(df, e=1):\n",
                "    return json.loads(df[df[\"eps_short\"] == f\"[1.0, {e}.0]\" ].iloc[-1]['costs_curve'])\n",
                "\n",
                "for e in [2,3,4,5]:\n",
                "    print(e)\n",
                "    plot_costs(get_cost_curve_for_eps(df, e=e), get_cost_curve_for_eps(df, e=e), [1.,e])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c482546d",
            "metadata": {},
            "outputs": [],
            "source": [
                "results_50_50"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b3df1fe0",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "name = \"vanish_weighted_ratio_plot_75_25__2\"\n",
                "\n",
                "OUT_PATH = os.path.join(DATA_DIR, name)\n",
                "with open(config_path, 'r') as stream:\n",
                "    config = yaml.safe_load(stream)\n",
                "\n",
                "df_v = pd.read_csv(os.path.join(OUT_PATH, voting_name))\n",
                "cost_curve = json.loads(df_v[\"costs_curve\"].iloc[0])    \n",
                "\n",
                "\n",
                "labels_answered = sum(np.array([under_budget(cost_curve[i], epsilons) for i in range(len(cost_curve))]))\n",
                "\n",
                "#labels_answered\n",
                "cost_curve\n",
                "#df_v\n",
                "plt.plot(cost_curve, label = \"1\")\n",
                "#plt.show()\n",
                "\n",
                "\n",
                "name = \"vanish_weighted_ratio_plot_75_25__3\"\n",
                "\n",
                "OUT_PATH = os.path.join(DATA_DIR, name)\n",
                "with open(config_path, 'r') as stream:\n",
                "    config = yaml.safe_load(stream)\n",
                "\n",
                "df_v = pd.read_csv(os.path.join(OUT_PATH, voting_name))\n",
                "cost_curve = json.loads(df_v[\"costs_curve\"].iloc[0])    \n",
                "\n",
                "\n",
                "labels_answered = sum(np.array([under_budget(cost_curve[i], epsilons) for i in range(len(cost_curve))]))\n",
                "\n",
                "#labels_answered\n",
                "cost_curve\n",
                "#df_v\n",
                "plt.plot(cost_curve, label = \"2\")\n",
                "plt.legend()\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ef48cff6",
            "metadata": {},
            "outputs": [],
            "source": [
                "list(zip(*weighted_labels_generated))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3c2cdf99",
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "eps_s  = np.log(np.array([4,8,16]))\n",
                "dists = ((.25, .75), (.5, .5), (.75, .25))\n",
                "\n",
                "relative_weights = []\n",
                "for dist in dists:\n",
                "    ratio = dist[0]/dist[1]\n",
                "    print(f\"Ratio is {np.around(ratio)}\")\n",
                "    ws = []\n",
                "    for eps in eps_s:\n",
                "        \n",
                "        w = ratio * (eps / (np.log(2)+eps))\n",
                "\n",
                "        ws.append(np.around(w,2))\n",
                "    \n",
                "    relative_weights.append(ws)\n",
                "relative_weights = np.array(relative_weights).T\n",
                "for ws in relative_weights:\n",
                "    \n",
                "    print(ws)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "patient-storm",
            "metadata": {},
            "outputs": [],
            "source": [
                "res = {eps : [] for eps in epsilons}\n",
                "\n",
                "\n",
                "for e in epsilons:\n",
                "    for d in distributions:\n",
                "\n",
                "        #data = df[(df['budgets_linear'] == str([CONSTANT * 1.0, CONSTANT * 1.0 * e])) &\n",
                "        #          (df['distribution'] == str({'all': (1 - d, d)}))]\n",
                "        data = df\n",
                "        u = round(np.mean(data[data['collector'] == 'uGNMax']['accuracy']) * 100, 2)\n",
                "        v = round(np.mean(data[data['collector'] == 'vGNMax']['accuracy']) * 100, 2)\n",
                "        w = round(np.mean(data[data['collector'] == 'wGNMax']['accuracy']) * 100, 2)\n",
                "        res[e].append((u, v, w))\n",
                "        \n",
                "print(algo)\n",
                "print(experiment)\n",
                "print('Table of average voting accuracy per personalization.\\n')\n",
                "print('average of baseline GNMax:', round(np.mean(df_vb['accuracy']) * 100, 2))\n",
                "\n",
                "pd.DataFrame(res, index=distributions).T\n",
                "      "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3c3145ca",
            "metadata": {},
            "outputs": [],
            "source": [
                "res = {eps : [] for eps in epsilons}\n",
                "for e in epsilons:\n",
                "    for d in distributions:\n",
                "        #data = df[(df['budgets_linear'] == str([CONSTANT * 1.0, CONSTANT * 1.0 * e])) &\n",
                "        #          (df['distribution'] == str({'all': (1 - d, d)}))]\n",
                "        data = df\n",
                "        u = round(np.mean(data[data['collector'] == 'uGNMax']['n_votings']) * 100, 2)\n",
                "        v = round(np.mean(data[data['collector'] == 'vGNMax']['n_votings']) * 100, 2)\n",
                "        w = round(np.mean(data[data['collector'] == 'wGNMax']['n_votings']) * 100, 2)\n",
                "        res[e].append((u, v, w))\n",
                "\n",
                "print(experiment)\n",
                "\n",
                "print(algo)\n",
                "print('Table of average n_votings per personalization.\\n')\n",
                "print('average of baseline GNMax:', round(np.mean(df_vb['n_votings']) * 100, 2))\n",
                "pd.DataFrame(res, index=distributions).T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4aeba479",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_t\n",
                "\n",
                "# TODO: plot histogram of teacher accuracies\n",
                "plt.title(\"Histogram of Teacher Accuracies\")\n",
                "plt.hist(df_t[\"test_accuracy\"], bins =100)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bcb7322a",
            "metadata": {},
            "outputs": [],
            "source": [
                "print('Statistics on voting accuracies (in %):')\n",
                "\n",
                "va_min = round(np.min(df_v['accuracy']) * 100, 2)\n",
                "va_max = round(np.max(df_v['accuracy']) * 100, 2)\n",
                "va_avg = round(np.mean(df_v['accuracy']) * 100, 2)\n",
                "va_std = round(np.std(df_v['accuracy']) * 100, 2)\n",
                "\n",
                "bva_min = round(np.min(df_vb['accuracy']) * 100, 2)\n",
                "bva_max = round(np.max(df_vb['accuracy']) * 100, 2)\n",
                "bva_avg = round(np.mean(df_vb['accuracy']) * 100, 2)\n",
                "bva_std = round(np.std(df_vb['accuracy']) * 100, 2)\n",
                "\n",
                "print('min:', va_min)\n",
                "print('max:', va_max)\n",
                "print('avg:', va_avg)\n",
                "print('std:', va_std)\n",
                "print('\\nbaselines:')\n",
                "print('min:', bva_min)\n",
                "print('max:', bva_max)\n",
                "print('avg:', bva_avg)\n",
                "print('std:', bva_std)\n",
                "\n",
                "pd.set_option(\"display.max_columns\", None)\n",
                "print(df_v.columns)\n",
                "df_v.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fff5ef83",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_v[\"costs_curve\"].iloc[0]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b11c6027",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "plt.plot([i[0] for i in cc])\n",
                "#plt.plot([i[1] for i in cc])\n",
                "#plt.plot([i[2] for i in cc])\n",
                "plt.show()\n",
                "\n",
                "plt.plot([i[0] for i in cc])\n",
                "plt.plot([i[1] for i in cc])\n",
                "plt.plot([i[2] for i in cc])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a3a73135",
            "metadata": {},
            "outputs": [],
            "source": [
                "np.exp(.25)/np.exp(.01)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "441e4b9b",
            "metadata": {},
            "outputs": [],
            "source": [
                "c"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8b447f89",
            "metadata": {},
            "outputs": [],
            "source": [
                "a,b,c = 0.01, 0.2, 1.0\n",
                "\n",
                "t = 250 * (((a/a) * .34) + ((b/a) * .43 ) + ((c/a) * .23 ))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "db6eb72e",
            "metadata": {},
            "outputs": [],
            "source": [
                "a,b,c = 1, 2, 3\n",
                "print(np.exp(b)/np.exp(a))\n",
                "print(np.exp(c)/np.exp(b))\n",
                "print(np.exp(a)/np.exp(.2))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3326ab56",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5d8233d7",
            "metadata": {},
            "outputs": [],
            "source": [
                "# PATE:\n",
                "df_v[\"costs_curve\"].iloc[0]\n",
                "import json\n",
                "cc = json.loads(df_vb[\"costs_curve\"].iloc[0])\n",
                "\n",
                "plt.plot([i[0] for i in cc])\n",
                "#plt.plot([i[1] for i in cc])\n",
                "#plt.plot([i[2] for i in cc])\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "automatic-canon",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df_s\n",
                "\n",
                "epsilons = [2, 4, 8]\n",
                "distributions = [0.25, 0.5, 0.75]\n",
                "\n",
                "res = {\n",
                "    2: [],\n",
                "    4: [],\n",
                "    8: [],\n",
                "}\n",
                "for e in epsilons:\n",
                "    for d in distributions:\n",
                "        data = df[(df['budgets_linear'] == str([CONSTANT * 1.0, CONSTANT * 1.0 * e])) &\n",
                "                  (df['distribution'] == str({'all': (1 - d, d)}))]\n",
                "        t = round(np.mean(data['n_labels']), 2)\n",
                "        u = round(np.mean(data[data['collector'] == 'uGNMax']['n_labels']), 2)\n",
                "        v = round(np.mean(data[data['collector'] == 'vGNMax']['n_labels']), 2)\n",
                "        w = round(np.mean(data[data['collector'] == 'wGNMax']['n_labels']), 2)\n",
                "        res[e].append((u, v, w))\n",
                "\n",
                "print('Table of average number of produced labels per personalization.\\n')\n",
                "for e in [1, 2, 4, 8]:\n",
                "    x = math.log(CONSTANT * 1.0 * e)\n",
                "    print(f'GNMax with budget {CONSTANT} * {e}:',\n",
                "          round(np.mean(df_sb[df_sb['limit'] == f'({x},)']['n_labels']), 2))\n",
                "pd.DataFrame(res, index=distributions).T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "lucky-exchange",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df_s\n",
                "\n",
                "epsilons = [2, 4, 8]\n",
                "distributions = [0.25, 0.5, 0.75]\n",
                "\n",
                "res = {\n",
                "    2: [],\n",
                "    4: [],\n",
                "    8: [],\n",
                "}\n",
                "for e in epsilons:\n",
                "    for d in distributions:\n",
                "        data = df[(df['budgets_linear'] == str([CONSTANT * 1.0, CONSTANT * 1.0 * e])) &\n",
                "                  (df['distribution'] == str({'all': (1 - d, d)}))]\n",
                "        u = round(np.mean(data[data['collector'] == 'uGNMax']['test_accuracy']) * 100, 2)\n",
                "        v = round(np.mean(data[data['collector'] == 'vGNMax']['test_accuracy']) * 100, 2)\n",
                "        w = round(np.mean(data[data['collector'] == 'wGNMax']['test_accuracy']) * 100, 2)\n",
                "        res[e].append((u, v, w))\n",
                "        \n",
                "print('Table of average accuracy (in %) per personalization.\\n')\n",
                "for e in [1, 2, 4, 8]:\n",
                "    x = math.log(CONSTANT * 1.0 * e)\n",
                "    print(f'GNMax with budget {CONSTANT} * {e}:',\n",
                "          round(np.mean(df_sb[df_sb['limit'] == f'({x},)']['test_accuracy']) * 100, 2))\n",
                "pd.DataFrame(res, index=distributions).T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "vocal-lebanon",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df_s\n",
                "\n",
                "epsilons = [2, 4, 8]\n",
                "distributions = [0.25, 0.5, 0.75]\n",
                "\n",
                "res = {\n",
                "    2: [],\n",
                "    4: [],\n",
                "    8: [],\n",
                "}\n",
                "for e in epsilons:\n",
                "    for d in distributions:\n",
                "        data = df[(df['budgets_linear'] == str([CONSTANT * 1.0, CONSTANT * 1.0 * e])) &\n",
                "                  (df['distribution'] == str({'all': (1 - d, d)}))]\n",
                "        t = data['avg_budget'].iloc[0]\n",
                "        res[e].append(round(np.mean(df_sb[df_sb['limit'] == str((t,))]['n_labels']), 2))\n",
                "\n",
                "print('Table of average number of labels for non-personalized GNMax with average budget per personalization.\\n')\n",
                "pd.DataFrame(res, index=distributions).T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "desirable-opera",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = df_s\n",
                "\n",
                "epsilons = [2, 4, 8]\n",
                "distributions = [0.25, 0.5, 0.75]\n",
                "\n",
                "res = {\n",
                "    2: [],\n",
                "    4: [],\n",
                "    8: [],\n",
                "}\n",
                "for e in epsilons:\n",
                "    for d in distributions:\n",
                "        data = df[(df['budgets_linear'] == str([CONSTANT * 1.0, CONSTANT * 1.0 * e])) &\n",
                "                  (df['distribution'] == str({'all': (1 - d, d)}))]\n",
                "        t = data['avg_budget'].iloc[0]\n",
                "        res[e].append(round(np.mean(df_sb[df_sb['limit'] == str((t,))]['test_accuracy']) * 100, 2))\n",
                "\n",
                "print('Table of average accuracy (in %) for non-personalized GNMax with average budget per personalization.\\n')\n",
                "pd.DataFrame(res, index=distributions).T"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b9417150",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5970e897",
            "metadata": {},
            "outputs": [],
            "source": [
                "## Just in ccase:\n",
                "\n",
                "epsilons_= [1.,2.,3.]\n",
                "epsilons_2 = [ np.around(np.log(2),2), np.around(np.log(8),2)]\n",
                "pate_epsilons = epsilons_\n",
                "\n",
                "\n",
                "experiments = [\"weight\", \"vanish\", \"mnist_upsample_2\", \"mnist_upsample_row_2\" , \"upsample_figure_2\"]\n",
                "experiments = [\"upsample_figure_2\"]\n",
                "\n",
                "experiments = [\"vanish\", \"mnist_vanish_row_2__2\"]\n",
                "\n",
                "yaml_base_path = os.path.join(HOME,\"code/personalized-pate/per-point-pate/experiment_plans/set_5_paper_submission/\")\n",
                "DATA_DIR = os.path.join(HOME, \"datadrive_individualized_pate/\")\n",
                "\n",
                "\n",
                "BASELINE_PATH= f\"{DATA_DIR}/pate/\"\n",
                "\n",
                "pate_config_path = os.path.join(yaml_base_path, \"mnist_pate.yaml\")\n",
                "df_vb = pd.read_csv(os.path.join(BASELINE_PATH, voting_name))\n",
                "with open(pate_config_path, 'r') as stream:\n",
                "    pate_config = yaml.safe_load(stream)\n",
                "cost_curve_b = json.loads(df_vb[\"costs_curve\"].iloc[0])\n",
                "\n",
                "labels_answered_b = sum(np.array([under_budget(cost_curve_b[i], pate_epsilons) for i in range(len(cost_curve_b))]))\n",
                "\n",
                "print(f\"PATE - labels_answered: {labels_answered_b}\")\n",
                "\n",
                "for experiment in experiments:  \n",
                "    algo_name = get_algo_name(experiment)\n",
                "    \n",
                "    if \"mnist\" in experiment:\n",
                "        yaml_name = f\"{experiment}.yaml\"\n",
                "    else:\n",
                "        yaml_name = f\"mnist_{experiment}.yaml\"    \n",
                "    config_path = os.path.join(yaml_base_path, yaml_name)\n",
                "    \n",
                "    \n",
                "    \n",
                "    OUT_PATH = os.path.join(DATA_DIR, experiment)\n",
                "\n",
                "    df_v = pd.read_csv(os.path.join(OUT_PATH, voting_name))\n",
                "\n",
                "    experiment = f\"{experiment}\" if \"mnist\" in experiment else f\"mnist_{experiment}\" \n",
                "\n",
                "    \n",
                "    # baseline\n",
                "    with open(config_path, 'r') as stream:\n",
                "        config = yaml.safe_load(stream)\n",
                "\n",
                "    algo = list(config[\"pate\"][\"budgets\"].keys())[0]\n",
                "    #epsilons = list(config[\"pate\"][\"budgets\"].values())[0][0]\n",
                "    distributions = config[\"pate\"][\"distributions\"][0][0]\n",
                "     # list(config[\"pate\"][\"budgets\"].values())[0][0]\n",
                "\n",
                "\n",
                "    cost_curve = json.loads(df_v[\"costs_curve\"].iloc[0])\n",
                "      \n",
                "    if len(cost_curve[0]) ==2:\n",
                "        \n",
                "        epsilons = epsilons_2\n",
                "    else: #if len(cost_curve[0]) == 3:\n",
                "        epsilons = epsilons_\n",
                "    # PLOT VOTING MECHANISM VS LABEL COUNT\n",
                "    print(f\"epsilons : {epsilons}\")\n",
                "\n",
                "    labels_answered = sum(np.array([under_budget(cost_curve[i], epsilons) for i in range(len(cost_curve))]))\n",
                "    \n",
                "    labels_answered1 = sum(np.array([cost_curve[i][0] < epsilons[0] for i in range(len(cost_curve))]))\n",
                "    if len(cost_curve[0]) >1:\n",
                "        labels_answered2 = sum(np.array([cost_curve[i][1] < epsilons[1] for i in range(len(cost_curve))]))\n",
                "    if len(cost_curve[0]) >2:\n",
                "        labels_answered3 = sum(np.array([cost_curve[i][2] < epsilons[2] for i in range(len(cost_curve))]))\n",
                "    \n",
                "    c1 = \"mediumpurple\"\n",
                "    c2 = \"blue\"\n",
                "    \n",
                "    plt.figure(figsize= (10,10))\n",
                "    plt.title(f\"{experiment}\", fontsize=18)\n",
                "    x_range = min(len(cost_curve), 2000)\n",
                "    plt.plot([np.array(cost_curve[i][0]) for i in range(labels_answered)], \"-\", c= c1, label = f\"{algo_name} (low)\")\n",
                "    plt.plot([np.array(cost_curve[i][0]) for i in range(x_range)], \":\", c = c1)\n",
                "    if len(cost_curve[0])>1:\n",
                "        plt.plot([np.array(cost_curve[i][1]) for i in range(labels_answered)], \"-\", c= c2, label = f\"{algo_name} (high)\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "        plt.plot([np.array(cost_curve[i][1]) for i in range(x_range)], \":\", c = c2) #, labels = (\"1\", \"2\", \"3\"))\n",
                "\n",
                "    if len(cost_curve[0]) >2:\n",
                "        plt.plot([np.array(cost_curve[i][2]) for i in range(labels_answered)], \"-\", c = \"g\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "        plt.plot([np.array(cost_curve[i][2]) for i in range(x_range)], \":\", c= \"g\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "    \n",
                "    \n",
                "    plt.axvline(x=labels_answered1, c= c1)\n",
                "    plt.axvline(x=labels_answered2, c= c2)\n",
                "    if len(cost_curve[0]) >2:\n",
                "        plt.axvline(x=labels_answered3, c= 'g')\n",
                "\n",
                "    #plt.axhline(y=epsilons[0], color='r', linestyle='-', label = f\"Most Private (eps = {epsilons[0]})\")\n",
                "    #hack -hard code legends\n",
                "    plt.axhline(y=epsilons[0], color=c1, linestyle='-')\n",
                "    if len(epsilons) >1:\n",
                "        #plt.axhline(y=epsilons[1], color='b', linestyle='-', label = f\"Least Private (eps = {epsilons[1]})\")\n",
                "        # hack -hard code legends\n",
                "        plt.axhline(y=epsilons[1], color=c2, linestyle='-')\n",
                "        \n",
                "    if len(epsilons) >2:\n",
                "        plt.axhline(y=epsilons[2], color='g', linestyle='-', label = f\"eps = {epsilons[2]}\")\n",
                "    \n",
                "    \n",
                "    ##  PATE plots\n",
                "    plt.plot([np.array(cost_curve_b[i]) for i in range(labels_answered_b)], \"-\", c= \"tab:gray\", label = \"pate\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "    plt.plot([np.array(cost_curve_b[i]) for i in range(min(len(cost_curve_b), 2000))], \":\", c = \"tab:gray\") #, labels = (\"1\", \"2\", \"3\"))\n",
                "    \n",
                "    plt.axvline(x=labels_answered_b, c= \"tab:gray\")\n",
                "        #(0.1, 0.2, 0.5, 0.3)\n",
                "        \n",
                "    plt.ylabel(\"Privacy Budget\", fontsize=18)\n",
                "    plt.xlabel(\"Labels Answered\", fontsize=18)\n",
                "    plt.legend(fontsize=12)\n",
                "    plt.show()\n",
                "\n",
                "    #print(f\"PATE - number of votes: {df_vb['n_votings'].mean()}\")\n",
                "\n",
                "\n",
                "    print(\"-------\")\n",
                "    #print(f\"{experiment} - {algo}: number of votes: {df_v['n_votings'].mean()}\")\n",
                "    print(f\"{experiment} - labels_answered: {labels_answered}\")\n",
                "    print(f\"{experiment} - labels_answered (0): {labels_answered1}\")\n",
                "    if len(cost_curve[0])>1:\n",
                "        print(f\"{experiment} - labels_answered (1):  {labels_answered2}\")\n",
                "    if len(cost_curve[0])>2:\n",
                "        print(f\"{experiment} - labels_answered (2): {labels_answered3}\")\n",
                "\n",
                "    print(f\"{experiment} - {algo}: accuracy: {df_v['accuracy'].mean()}\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
